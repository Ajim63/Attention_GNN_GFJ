{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.special as special\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, GRU, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, LeakyReLU, GRU, Concatenate, Reshape, Softmax, Attention\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.models import Model\n",
    "#from keras.layers import LeakyReLU\n",
    "\n",
    "from spektral.layers import  GCSConv, DiffusionConv, GATConv, ARMAConv, GCNConv\n",
    "\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_seq2seq_io_data(\n",
    "        df, x_offsets, y_offsets, add_time_in_day=True, add_day_in_week=False, scaler=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate samples from\n",
    "    :param df:\n",
    "    :param x_offsets:\n",
    "    :param y_offsets:\n",
    "    :param add_time_in_day:\n",
    "    :param add_day_in_week:\n",
    "    :param scaler:\n",
    "    :return:\n",
    "    # x: (epoch_size, input_length, num_nodes, input_dim)\n",
    "    # y: (epoch_size, output_length, num_nodes, output_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples, num_nodes = df.shape\n",
    "    data = np.expand_dims(df.values, axis=-1)\n",
    "    data_list = [data]\n",
    "    if add_time_in_day:\n",
    "        time_ind = (df.index.values - df.index.values.astype(\"datetime64[D]\")) / np.timedelta64(1, \"D\")\n",
    "        time_in_day = np.tile(time_ind, [1, num_nodes, 1]).transpose((2, 1, 0))\n",
    "        data_list.append(time_in_day)\n",
    "    if add_day_in_week:\n",
    "        day_in_week = np.zeros(shape=(num_samples, num_nodes, 7))\n",
    "        day_in_week[np.arange(num_samples), :, df.index.dayofweek] = 1\n",
    "        data_list.append(day_in_week)\n",
    "\n",
    "    data = np.concatenate(data_list, axis=-1)\n",
    "    # epoch_len = num_samples + min(x_offsets) - max(y_offsets)\n",
    "    x, y = [], []\n",
    "    # t is the index of the last observation.\n",
    "    min_t = abs(min(x_offsets))\n",
    "    max_t = abs(num_samples - abs(max(y_offsets)))  # Exclusive\n",
    "    for t in range(min_t, max_t):\n",
    "        x_t = data[t + x_offsets, ...]\n",
    "        y_t = data[t + y_offsets, ...]\n",
    "        x.append(x_t)\n",
    "        y.append(y_t)\n",
    "    x = np.stack(x, axis=0)\n",
    "    y = np.stack(y, axis=0)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss(dic):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(dic['loss'], label='Training loss ')\n",
    "    plt.plot(dic['val_loss'], label='Validation loss ')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title('train and validation loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def MSE(original, imputed):\n",
    "    # calculate Mean Squared Error\n",
    "    return np.square(original-imputed).mean()\n",
    "\n",
    "def MPE(y_true, y_pred, threshold=0.1):\n",
    "    v = np.copy(y_true)\n",
    "    np.place(v, v==0, threshold)\n",
    "    #v = np.clip(np.abs(y_true), threshold, None)\n",
    "    diff = np.abs((y_true - y_pred) / v)\n",
    "    return np.mean(diff, axis=-1).mean()\n",
    "\n",
    "\"\"\"\n",
    "def R_squared(original, predicted):\n",
    "    Differ = np.square(original-predicted)\n",
    "    m = np.mean(original) \n",
    "    denom = np.square(original - m)\n",
    "    R_sq = 1 - ((Differ.sum())/denom.sum())\n",
    "    return R_sq\n",
    "\"\"\"\n",
    "def R_squared(original, predicted):\n",
    "    Differ = np.square(original-predicted)\n",
    "    #m = np.mean(original) \n",
    "    denom = np.square(original)\n",
    "    R_sq = 1 - ((Differ.sum())/denom.sum())\n",
    "    return R_sq\n",
    "\n",
    "def Get_performance(Y_true, Y_pred): \n",
    "    print (\"R2 : \", np.round(R_squared(Y_true, Y_pred), 4))\n",
    "    print (\"MSE\",  np.round(MSE(Y_true, Y_pred), 4))\n",
    "    print (\"MPE\", np.round(MPE(Y_true, Y_pred), 4))\n",
    "    \n",
    "    return (np.round(R_squared(Y_true, Y_pred), 4), np.round(MSE(Y_true, Y_pred), 4), np.round(MPE(Y_true, Y_pred), 4)) \n",
    "        \n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "def mape(y_true, y_pred, threshold=0.1):\n",
    "    v = np.clip(np.abs(y_true), threshold, None)\n",
    "    diff = np.abs((y_true - y_pred) / v)\n",
    "    return 100.0 * np.mean(diff, axis=-1).mean()\n",
    "\n",
    "def get_metrics(y, yp):\n",
    "    return {\n",
    "        \"rmse\": np.round(rmse(y, yp), 4),\n",
    "        \"mae\": np.round(mae(y, yp), 4),\n",
    "        \"mape\": np.round(mape(y, yp),4),\n",
    "        #\"MPE\": np.round(MPE(y, yp), 4),\n",
    "        #\"R2\": np.round(R_squared(y, yp),4)\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load and preview dataset\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthetic = pd.read_csv('Synthetic_Data.csv', parse_dates=['date'])\n",
    "Synthetic['ID'] = Synthetic.groupby([\"country\", \"Series\", 'S_type']).ngroup()\n",
    "Synthetic.set_index('date', inplace =True)\n",
    "\n",
    "Synthetic['ret'] = Synthetic.groupby('ID')['value'].pct_change()\n",
    "Synthetic.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthetic_char = Synthetic[['country_gdp_factor', 'weekend_boost_factor','product_linear_trend','random_seris_type',\n",
    "                            'white_noise', 'holiday_trend_factor', 'eu_industry_product_factor', 'product_seasonal_trend_factor',\n",
    "                            'random_series_factor', 'wavelength', 'amplitude', 'phase', 'ID']]\n",
    "\n",
    "Synthetic_char= Synthetic_char.reset_index().set_index(['date', 'ID'])\n",
    "\n",
    "Synthetic_ret = Synthetic[['ID', 'ret']].pivot(columns='ID', values='ret')\n",
    "Synthetic_val = Synthetic[['ID', 'value']].pivot(columns='ID', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_day = len(Synthetic_char.groupby('date').size())\n",
    "n_firms = len(Synthetic_char.groupby('ID').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many time lag I wanna use\n",
    "n_lag = 36\n",
    "#how many time period I wanna predict\n",
    "n_forward = 1\n",
    "\n",
    "x_offsets = np.sort(np.arange(-n_lag+1, 1, 1))\n",
    "y_offsets = np.sort(np.arange(1, n_forward+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_graph_seq2seq_io_data(\n",
    "    Synthetic_ret,\n",
    "    x_offsets=x_offsets,\n",
    "    y_offsets=y_offsets,\n",
    "    add_time_in_day=False,\n",
    "    add_day_in_week=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Standardization\n",
    "#standardization\n",
    "scaler = StandardScaler()\n",
    "#scaler.fit(data)\n",
    "data_stand = scaler.fit_transform(Synthetic_char)\n",
    "#data_stand = pd.DataFrame(data_stand, index=data.index,  columns=data.columns)  \n",
    "features = data_stand.reshape(n_day, n_firms, Synthetic_char.shape[1])\n",
    "features = features[n_lag-1:-n_forward,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose(x, (0, 2, 1, 3))\n",
    "y = np.transpose(y, (0, 2, 1, 3))\n",
    "\n",
    "#reshape to made three dimensional tensor\n",
    "x = x.reshape(x.shape[0],x.shape[1],x.shape[2] )\n",
    "y = y.reshape(y.shape[0],y.shape[1],y.shape[2] )\n",
    "\n",
    "#x = np.transpose(x, (0, 2, 1))\n",
    "#y = np.transpose(y, (0, 2, 1))\n",
    "\n",
    "\n",
    "\n",
    "x = x.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajim/.local/lib/python3.5/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "AdPos = np.empty([x.shape[0], x.shape[1], x.shape[1]])\n",
    "AdNeg = np.empty([x.shape[0], x.shape[1], x.shape[1]])\n",
    "\n",
    "for i in range(0, x.shape[0]):\n",
    "    aa = np.corrcoef(x[i],rowvar=True)\n",
    "    P_val =  np.abs((aa*np.sqrt(n_lag-2))/(np.sqrt(1-np.square(aa))))\n",
    "    P_val  = np.nan_to_num(P_val, nan=0.0, posinf=0, neginf=0)\n",
    "    ab = n_lag/2 - 1\n",
    "    P_val = 2*special.btdtr(ab, ab, 0.5*(1 - abs(np.float64(aa))))\n",
    "    P_val = np.nan_to_num(P_val, nan=0.0, posinf=0, neginf=0)\n",
    "    P_val  = np.where(P_val>0.05, 0, 1)\n",
    "    \n",
    "    Adjac = aa*P_val\n",
    "    #adj_matrix[i] = P_val \n",
    "    \n",
    "    AdPos[i] =  np.where(Adjac > 0,1,0 )\n",
    "    AdNeg[i] =  np.where(Adjac < 0,1,0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = np.ones((1059, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 50, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:600,:,:]\n",
    "y_train = y[:600,:,:]\n",
    "\n",
    "\n",
    "\n",
    "x_val = x[600:800,:,:]\n",
    "y_val = y[600:800,:,:]\n",
    "\n",
    "\n",
    "x_test = x[800:,:,:]\n",
    "y_test = y[800:,:,:]\n",
    "\n",
    "\n",
    "features_train  = features[:600,:,:]\n",
    "features_val  =   features[600:800,:,:]\n",
    "features_test  =  features[800:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "adj_train = Adj[:600,:,:]\n",
    "adj_val = Adj[600:800,:,:]\n",
    "adj_test = Adj[800:,:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size =24\n",
    "epochs = 100\n",
    "seed = 42\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Model\n",
    "\n",
    "inputs_ret = Input(shape=(x.shape[1], x.shape[2], ))\n",
    "inputs_feat = Input(shape=(features.shape[1], features.shape[2], ))\n",
    "inputs_adj = Input(shape=(features.shape[1],features.shape[1], ))\n",
    "\n",
    "#inputs_3 = Input(shape=(data_shape[1],k, ))\n",
    "\n",
    "GAT_output_P, Att_weights_P =  GATConv(16, attn_heads=4, concat_heads=True, dropout_rate=0.3, return_attn_coef=True, \n",
    "                                   activation='relu', use_bias=False)([inputs_ret, inputs_adj])\n",
    "Att_weights_P = tf.math.reduce_mean(Att_weights_P, axis=2)\n",
    "\n",
    "GAT_output_P_2 =  GATConv(16, attn_heads=4, concat_heads=True, dropout_rate=0.3, return_attn_coef=False, \n",
    "                        activation='relu', use_bias=True)([inputs_feat, inputs_adj])\n",
    "\n",
    "\n",
    "con_out_P_2 = Concatenate(axis=-1)([ GAT_output_P_2, GAT_output_P])\n",
    "\n",
    "dense_out = Dense(8, activation='linear')(con_out_P_2)\n",
    "dense_out = Dropout(0.2)(dense_out)\n",
    "outputs = Dense(1)(dense_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 50, 12)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 50, 50)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50, 36)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gat_conv_1 (GATConv)            (None, 50, 64)       896         input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gat_conv (GATConv)              ((None, 50, 64), (No 2432        input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 128)      0           gat_conv_1[0][0]                 \n",
      "                                                                 gat_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 8)        1032        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 8)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 1)        9           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,369\n",
      "Trainable params: 4,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(inputs=[inputs_ret, inputs_feat, inputs_adj], outputs=outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[\"mae\", \"mape\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 0s 19ms/step - mape: 948.1227 - loss: 0.0194 - mae: 0.1047 - val_loss: 0.0074 - val_mape: 329.7380 - val_mae: 0.0683\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 500.0723 - loss: 0.0082 - mae: 0.0717 - val_loss: 0.0062 - val_mape: 392.1599 - val_mae: 0.0627\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 488.4259 - loss: 0.0069 - mae: 0.0660 - val_loss: 0.0059 - val_mape: 358.8492 - val_mae: 0.0613\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 483.5336 - loss: 0.0066 - mae: 0.0644 - val_loss: 0.0057 - val_mape: 342.0595 - val_mae: 0.0604\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 435.7394 - loss: 0.0063 - mae: 0.0635 - val_loss: 0.0057 - val_mape: 338.9361 - val_mae: 0.0600\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 409.7964 - loss: 0.0063 - mae: 0.0632 - val_loss: 0.0056 - val_mape: 330.9966 - val_mae: 0.0598\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 432.0255 - loss: 0.0062 - mae: 0.0625 - val_loss: 0.0056 - val_mape: 334.0385 - val_mae: 0.0598\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 454.8125 - loss: 0.0061 - mae: 0.0621 - val_loss: 0.0056 - val_mape: 340.9706 - val_mae: 0.0595\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 479.9496 - loss: 0.0061 - mae: 0.0619 - val_loss: 0.0056 - val_mape: 337.7073 - val_mae: 0.0595\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 416.6941 - loss: 0.0060 - mae: 0.0616 - val_loss: 0.0056 - val_mape: 353.1614 - val_mae: 0.0592\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 445.6930 - loss: 0.0059 - mae: 0.0613 - val_loss: 0.0056 - val_mape: 339.0939 - val_mae: 0.0593\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 436.3246 - loss: 0.0059 - mae: 0.0611 - val_loss: 0.0056 - val_mape: 336.0274 - val_mae: 0.0595\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 421.0804 - loss: 0.0058 - mae: 0.0609 - val_loss: 0.0056 - val_mape: 342.2551 - val_mae: 0.0593\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 415.5255 - loss: 0.0059 - mae: 0.0609 - val_loss: 0.0056 - val_mape: 340.7456 - val_mae: 0.0593\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 456.0218 - loss: 0.0058 - mae: 0.0608 - val_loss: 0.0055 - val_mape: 342.7512 - val_mae: 0.0592\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 472.8774 - loss: 0.0058 - mae: 0.0606 - val_loss: 0.0055 - val_mape: 345.2303 - val_mae: 0.0591\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 407.8050 - loss: 0.0058 - mae: 0.0605 - val_loss: 0.0055 - val_mape: 349.4950 - val_mae: 0.0591\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 384.8058 - loss: 0.0058 - mae: 0.0604 - val_loss: 0.0055 - val_mape: 343.2254 - val_mae: 0.0591\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 350.5454 - loss: 0.0057 - mae: 0.0604 - val_loss: 0.0055 - val_mape: 343.6999 - val_mae: 0.0590\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 448.2853 - loss: 0.0058 - mae: 0.0604 - val_loss: 0.0055 - val_mape: 339.5374 - val_mae: 0.0592\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.3585 - loss: 0.0057 - mae: 0.0602 - val_loss: 0.0055 - val_mape: 343.5091 - val_mae: 0.0590\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 445.5191 - loss: 0.0057 - mae: 0.0602 - val_loss: 0.0055 - val_mape: 349.7765 - val_mae: 0.0590\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 421.2611 - loss: 0.0057 - mae: 0.0602 - val_loss: 0.0055 - val_mape: 351.4013 - val_mae: 0.0589\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.2450 - loss: 0.0057 - mae: 0.0603 - val_loss: 0.0055 - val_mape: 356.6023 - val_mae: 0.0588\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.7111 - loss: 0.0057 - mae: 0.0600 - val_loss: 0.0055 - val_mape: 344.4034 - val_mae: 0.0591\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.5837 - loss: 0.0057 - mae: 0.0602 - val_loss: 0.0055 - val_mape: 346.7997 - val_mae: 0.0590\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 427.9699 - loss: 0.0057 - mae: 0.0601 - val_loss: 0.0055 - val_mape: 346.0462 - val_mae: 0.0591\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 408.3681 - loss: 0.0057 - mae: 0.0601 - val_loss: 0.0055 - val_mape: 354.8014 - val_mae: 0.0589\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 436.1406 - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0055 - val_mape: 353.6253 - val_mae: 0.0590\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 412.6142 - loss: 0.0057 - mae: 0.0601 - val_loss: 0.0055 - val_mape: 344.6834 - val_mae: 0.0589\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 379.3637 - loss: 0.0057 - mae: 0.0600 - val_loss: 0.0055 - val_mape: 348.9744 - val_mae: 0.0589\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 385.5338 - loss: 0.0057 - mae: 0.0600 - val_loss: 0.0055 - val_mape: 353.2329 - val_mae: 0.0590\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 437.0444 - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0055 - val_mape: 364.3309 - val_mae: 0.0588\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 425.4096 - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0055 - val_mape: 357.3322 - val_mae: 0.0589\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 322.6864 - loss: 0.0057 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 356.1036 - val_mae: 0.0589\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.5658 - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0055 - val_mape: 360.9207 - val_mae: 0.0589\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.6009 - loss: 0.0057 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 353.0969 - val_mae: 0.0589\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 367.1180 - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0055 - val_mape: 355.9778 - val_mae: 0.0589\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 344.1998 - loss: 0.0056 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 357.3390 - val_mae: 0.0589\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.0024 - loss: 0.0056 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 360.8741 - val_mae: 0.0588\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.9250 - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0055 - val_mape: 362.4146 - val_mae: 0.0589\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 374.7034 - loss: 0.0057 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 355.1560 - val_mae: 0.0589\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 437.4675 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 351.2668 - val_mae: 0.0589\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 411.8160 - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0055 - val_mape: 352.1170 - val_mae: 0.0588\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 426.5209 - loss: 0.0056 - mae: 0.0598 - val_loss: 0.0055 - val_mape: 354.4201 - val_mae: 0.0588\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.4119 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 359.0035 - val_mae: 0.0588\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.8924 - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0055 - val_mape: 354.4086 - val_mae: 0.0588\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 398.5379 - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0055 - val_mape: 356.0320 - val_mae: 0.0589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 389.0603 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 356.0229 - val_mae: 0.0587\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 360.4140 - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0055 - val_mape: 354.6846 - val_mae: 0.0588\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 419.0982 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 338.6541 - val_mae: 0.0589\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.6810 - loss: 0.0056 - mae: 0.0597 - val_loss: 0.0055 - val_mape: 355.0750 - val_mae: 0.0587\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 416.3093 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 356.2129 - val_mae: 0.0588\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 378.6434 - loss: 0.0056 - mae: 0.0594 - val_loss: 0.0055 - val_mape: 361.2347 - val_mae: 0.0586\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 404.6594 - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0055 - val_mape: 346.6065 - val_mae: 0.0588\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 391.8209 - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0055 - val_mape: 354.0062 - val_mae: 0.0587\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 429.1405 - loss: 0.0056 - mae: 0.0594 - val_loss: 0.0055 - val_mape: 364.7975 - val_mae: 0.0586\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.2305 - loss: 0.0056 - mae: 0.0596 - val_loss: 0.0055 - val_mape: 354.9639 - val_mae: 0.0586\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.9524 - loss: 0.0056 - mae: 0.0594 - val_loss: 0.0055 - val_mape: 349.0084 - val_mae: 0.0586\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 429.3261 - loss: 0.0056 - mae: 0.0594 - val_loss: 0.0054 - val_mape: 358.1791 - val_mae: 0.0586\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 391.0759 - loss: 0.0056 - mae: 0.0594 - val_loss: 0.0055 - val_mape: 344.4471 - val_mae: 0.0586\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.6774 - loss: 0.0056 - mae: 0.0593 - val_loss: 0.0054 - val_mape: 340.7318 - val_mae: 0.0586\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 443.0685 - loss: 0.0056 - mae: 0.0592 - val_loss: 0.0054 - val_mape: 339.1373 - val_mae: 0.0585\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 379.1194 - loss: 0.0055 - mae: 0.0591 - val_loss: 0.0054 - val_mape: 366.6044 - val_mae: 0.0582\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 358.6541 - loss: 0.0055 - mae: 0.0591 - val_loss: 0.0054 - val_mape: 351.1215 - val_mae: 0.0582\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.2027 - loss: 0.0055 - mae: 0.0589 - val_loss: 0.0054 - val_mape: 345.3423 - val_mae: 0.0580\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.6545 - loss: 0.0055 - mae: 0.0588 - val_loss: 0.0053 - val_mape: 352.6680 - val_mae: 0.0578\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 389.7063 - loss: 0.0054 - mae: 0.0585 - val_loss: 0.0053 - val_mape: 339.8373 - val_mae: 0.0575\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 337.4784 - loss: 0.0054 - mae: 0.0583 - val_loss: 0.0052 - val_mape: 346.1324 - val_mae: 0.0570\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.3121 - loss: 0.0053 - mae: 0.0578 - val_loss: 0.0051 - val_mape: 331.2479 - val_mae: 0.0564\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 379.3068 - loss: 0.0052 - mae: 0.0573 - val_loss: 0.0050 - val_mape: 320.2000 - val_mae: 0.0560\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 385.8009 - loss: 0.0051 - mae: 0.0568 - val_loss: 0.0048 - val_mape: 328.3792 - val_mae: 0.0549\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 350.9741 - loss: 0.0050 - mae: 0.0561 - val_loss: 0.0047 - val_mape: 306.3748 - val_mae: 0.0546\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 376.1010 - loss: 0.0049 - mae: 0.0556 - val_loss: 0.0046 - val_mape: 315.0744 - val_mae: 0.0534\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 401.1657 - loss: 0.0048 - mae: 0.0549 - val_loss: 0.0046 - val_mape: 358.8134 - val_mae: 0.0535\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 365.8360 - loss: 0.0047 - mae: 0.0548 - val_loss: 0.0044 - val_mape: 355.9407 - val_mae: 0.0524\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 377.8742 - loss: 0.0047 - mae: 0.0542 - val_loss: 0.0043 - val_mape: 316.0264 - val_mae: 0.0518\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 369.6064 - loss: 0.0046 - mae: 0.0539 - val_loss: 0.0042 - val_mape: 316.4049 - val_mae: 0.0517\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 437.8317 - loss: 0.0046 - mae: 0.0537 - val_loss: 0.0042 - val_mape: 323.6383 - val_mae: 0.0513\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 448.2577 - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0042 - val_mape: 319.4595 - val_mae: 0.0513\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 367.1680 - loss: 0.0045 - mae: 0.0535 - val_loss: 0.0042 - val_mape: 296.3357 - val_mae: 0.0509\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 466.3648 - loss: 0.0044 - mae: 0.0528 - val_loss: 0.0041 - val_mape: 314.7677 - val_mae: 0.0505\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 417.7807 - loss: 0.0044 - mae: 0.0528 - val_loss: 0.0041 - val_mape: 300.1336 - val_mae: 0.0504\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 450.4771 - loss: 0.0044 - mae: 0.0528 - val_loss: 0.0041 - val_mape: 315.2816 - val_mae: 0.0509\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 440.0679 - loss: 0.0044 - mae: 0.0528 - val_loss: 0.0041 - val_mape: 326.4656 - val_mae: 0.0503\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 328.5125 - loss: 0.0044 - mae: 0.0524 - val_loss: 0.0040 - val_mape: 326.3134 - val_mae: 0.0503\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 399.9678 - loss: 0.0044 - mae: 0.0525 - val_loss: 0.0040 - val_mape: 302.9600 - val_mae: 0.0500\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 421.8822 - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0040 - val_mape: 324.4219 - val_mae: 0.0500\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 337.4084 - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0040 - val_mape: 293.9525 - val_mae: 0.0503\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 425.3908 - loss: 0.0044 - mae: 0.0523 - val_loss: 0.0040 - val_mape: 291.9380 - val_mae: 0.0498\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 421.2553 - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0039 - val_mape: 328.2678 - val_mae: 0.0496\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 417.4535 - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0040 - val_mape: 328.7716 - val_mae: 0.0497\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 382.1033 - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0039 - val_mape: 327.6720 - val_mae: 0.0494\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 426.5061 - loss: 0.0043 - mae: 0.0519 - val_loss: 0.0039 - val_mape: 336.7319 - val_mae: 0.0497\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 475.7707 - loss: 0.0042 - mae: 0.0517 - val_loss: 0.0039 - val_mape: 338.4474 - val_mae: 0.0493\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 386.3164 - loss: 0.0042 - mae: 0.0515 - val_loss: 0.0040 - val_mape: 325.9102 - val_mae: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 374.5500 - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0040 - val_mape: 307.4622 - val_mae: 0.0498\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 479.4636 - loss: 0.0042 - mae: 0.0517 - val_loss: 0.0039 - val_mape: 305.3140 - val_mae: 0.0494\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 366.6324 - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0040 - val_mape: 292.1496 - val_mae: 0.0497\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 382.8343 - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0039 - val_mape: 321.1652 - val_mae: 0.0493\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 411.8847 - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0039 - val_mape: 342.5869 - val_mae: 0.0492\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 348.3065 - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0039 - val_mape: 312.4466 - val_mae: 0.0491\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 449.3950 - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0039 - val_mape: 311.1070 - val_mae: 0.0492\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 376.8110 - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0039 - val_mape: 313.6928 - val_mae: 0.0492\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 356.1659 - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0038 - val_mape: 357.4371 - val_mae: 0.0491\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 330.2756 - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0038 - val_mape: 344.4956 - val_mae: 0.0491\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 363.8625 - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0038 - val_mape: 324.9660 - val_mae: 0.0490\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 420.9898 - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0038 - val_mape: 325.0550 - val_mae: 0.0490\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 384.7629 - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0038 - val_mape: 334.7553 - val_mae: 0.0487\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 371.6165 - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0038 - val_mape: 342.7709 - val_mae: 0.0490\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 432.2819 - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0038 - val_mape: 322.8055 - val_mae: 0.0489\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 404.2659 - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0039 - val_mape: 362.7436 - val_mae: 0.0491\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 349.5308 - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0038 - val_mape: 327.0154 - val_mae: 0.0488\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 426.7494 - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0039 - val_mape: 342.3294 - val_mae: 0.0489\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 424.3831 - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0038 - val_mape: 331.7195 - val_mae: 0.0489\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.0348 - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0038 - val_mape: 347.4653 - val_mae: 0.0488\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 430.6935 - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0038 - val_mape: 349.8478 - val_mae: 0.0489\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 398.4152 - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0038 - val_mape: 323.3958 - val_mae: 0.0487\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 387.8303 - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0038 - val_mape: 372.1013 - val_mae: 0.0487\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 388.2088 - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0038 - val_mape: 350.9605 - val_mae: 0.0487\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 378.8472 - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0038 - val_mape: 349.1737 - val_mae: 0.0487\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 346.1600 - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0038 - val_mape: 336.9911 - val_mae: 0.0485\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 377.7235 - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0038 - val_mape: 342.8149 - val_mae: 0.0488\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 385.3560 - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0038 - val_mape: 329.6374 - val_mae: 0.0486\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 382.4284 - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0038 - val_mape: 331.7036 - val_mae: 0.0485\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.5494 - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0038 - val_mape: 320.7711 - val_mae: 0.0486\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.4292 - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0038 - val_mape: 341.9227 - val_mae: 0.0487\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 408.2234 - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0038 - val_mape: 344.0781 - val_mae: 0.0485\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 356.1882 - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0038 - val_mape: 329.0923 - val_mae: 0.0488\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 477.5397 - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0038 - val_mape: 329.0061 - val_mae: 0.0484\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 352.6502 - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0037 - val_mape: 327.6129 - val_mae: 0.0483\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.0498 - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0038 - val_mape: 334.3211 - val_mae: 0.0485\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 362.3614 - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0038 - val_mape: 316.2371 - val_mae: 0.0485\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 393.2777 - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0038 - val_mape: 326.9112 - val_mae: 0.0484\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 367.2247 - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0038 - val_mape: 357.6566 - val_mae: 0.0486\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 463.5289 - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0037 - val_mape: 314.6733 - val_mae: 0.0483\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 405.1381 - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0037 - val_mape: 340.2901 - val_mae: 0.0483\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 422.8533 - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0037 - val_mape: 330.7704 - val_mae: 0.0484\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 461.3141 - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0037 - val_mape: 340.2175 - val_mae: 0.0483\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 436.1163 - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0038 - val_mape: 347.8963 - val_mae: 0.0484\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 369.3644 - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0038 - val_mape: 373.3871 - val_mae: 0.0486\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 417.4944 - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0037 - val_mape: 346.3654 - val_mae: 0.0481\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 376.4876 - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0037 - val_mape: 327.2014 - val_mae: 0.0483\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.9015 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0038 - val_mape: 338.8745 - val_mae: 0.0483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.3748 - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0038 - val_mape: 317.9837 - val_mae: 0.0483\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.2294 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0037 - val_mape: 335.7043 - val_mae: 0.0482\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 383.7101 - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0037 - val_mape: 349.6010 - val_mae: 0.0481\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.3092 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0037 - val_mape: 326.5302 - val_mae: 0.0481\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.8699 - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0037 - val_mape: 340.8369 - val_mae: 0.0481\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 369.6276 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0037 - val_mape: 336.0631 - val_mae: 0.0483\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 374.2052 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0037 - val_mape: 333.1516 - val_mae: 0.0481\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 451.4656 - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0037 - val_mape: 339.6030 - val_mae: 0.0479\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 398.0783 - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0037 - val_mape: 352.6717 - val_mae: 0.0481\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 471.0182 - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0037 - val_mape: 348.4629 - val_mae: 0.0480\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 431.8760 - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 338.2094 - val_mae: 0.0479\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 405.8558 - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0037 - val_mape: 331.7648 - val_mae: 0.0478\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 395.9588 - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0037 - val_mape: 327.5613 - val_mae: 0.0478\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 448.1459 - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0037 - val_mape: 322.7505 - val_mae: 0.0479\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 358.1318 - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0037 - val_mape: 346.2959 - val_mae: 0.0482\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 350.9167 - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0037 - val_mape: 346.6750 - val_mae: 0.0479\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 387.9442 - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 327.9635 - val_mae: 0.0480\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 405.5711 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0036 - val_mape: 336.8161 - val_mae: 0.0478\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 368.3781 - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 342.2771 - val_mae: 0.0482\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 409.9294 - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 334.5681 - val_mae: 0.0479\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 456.2130 - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0037 - val_mape: 342.8371 - val_mae: 0.0479\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 443.3854 - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 352.6663 - val_mae: 0.0478\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 367.5689 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0036 - val_mape: 334.0479 - val_mae: 0.0477\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 318.1778 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 350.0143 - val_mae: 0.0477\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 347.9336 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 324.1351 - val_mae: 0.0478\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 439.4543 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 349.1965 - val_mae: 0.0477\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 328.7343 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 358.3999 - val_mae: 0.0477\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.2721 - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0037 - val_mape: 357.8938 - val_mae: 0.0479\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.7399 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 341.6447 - val_mae: 0.0476\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 364.6553 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0037 - val_mape: 351.8285 - val_mae: 0.0478\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 399.7060 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 343.9659 - val_mae: 0.0476\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.8078 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0037 - val_mape: 360.6207 - val_mae: 0.0479\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 341.2228 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0036 - val_mape: 354.0959 - val_mae: 0.0478\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 361.4245 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0036 - val_mape: 337.6275 - val_mae: 0.0476\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 439.0494 - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0037 - val_mape: 353.2910 - val_mae: 0.0477\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 370.4648 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 330.5156 - val_mae: 0.0475\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 385.3058 - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0037 - val_mape: 343.3972 - val_mae: 0.0477\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 408.8947 - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0036 - val_mape: 341.9330 - val_mae: 0.0475\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 389.7828 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 332.7449 - val_mae: 0.0475\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 334.0627 - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0036 - val_mape: 349.5009 - val_mae: 0.0475\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 383.4039 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0036 - val_mape: 343.6722 - val_mae: 0.0476\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 328.8456 - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0036 - val_mape: 355.9679 - val_mae: 0.0476\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 407.2249 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 348.4766 - val_mae: 0.0476\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 416.5373 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0036 - val_mape: 338.4331 - val_mae: 0.0474\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 403.1361 - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0036 - val_mape: 347.8594 - val_mae: 0.0475\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 367.0069 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0037 - val_mape: 355.0055 - val_mae: 0.0477\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 410.3626 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 337.9511 - val_mae: 0.0476\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 375.2061 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0036 - val_mape: 361.9981 - val_mae: 0.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.7254 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0036 - val_mape: 340.6426 - val_mae: 0.0476\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 362.1097 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 339.0203 - val_mae: 0.0476\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 399.3946 - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0036 - val_mape: 340.4520 - val_mae: 0.0475\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 400.5911 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 348.5678 - val_mae: 0.0475\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 407.7935 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0037 - val_mape: 375.2892 - val_mae: 0.0480\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 391.0393 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 352.1029 - val_mae: 0.0474\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 361.4213 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 357.7297 - val_mae: 0.0475\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 398.2909 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0037 - val_mape: 342.4641 - val_mae: 0.0477\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 354.5416 - loss: 0.0037 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 338.5847 - val_mae: 0.0474\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 427.1323 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 352.6365 - val_mae: 0.0477\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 415.0454 - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0036 - val_mape: 338.6703 - val_mae: 0.0476\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 396.0679 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 349.0223 - val_mae: 0.0474\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 420.4435 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 343.7745 - val_mae: 0.0475\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 419.5614 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 347.9059 - val_mae: 0.0475\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 418.2489 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 341.5944 - val_mae: 0.0475\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.5432 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 358.5599 - val_mae: 0.0474\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 405.3093 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 337.2543 - val_mae: 0.0474\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 364.5975 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 333.4306 - val_mae: 0.0475\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 470.2824 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 342.7476 - val_mae: 0.0475\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 329.0496 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0037 - val_mape: 351.8864 - val_mae: 0.0477\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 357.7814 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 339.6829 - val_mae: 0.0474\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.3809 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 358.8407 - val_mae: 0.0475\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 383.1628 - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mape: 338.8194 - val_mae: 0.0474\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 373.7489 - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0037 - val_mape: 332.8036 - val_mae: 0.0477\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 404.3117 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 360.3499 - val_mae: 0.0475\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 388.2582 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 336.8784 - val_mae: 0.0474\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 407.7285 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 346.2075 - val_mae: 0.0475\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 410.8209 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 346.3413 - val_mae: 0.0474\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 384.8968 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 349.4656 - val_mae: 0.0474\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 404.3152 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 341.6898 - val_mae: 0.0474\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 362.0230 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 334.0632 - val_mae: 0.0474\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 417.0214 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 347.0063 - val_mae: 0.0475\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.9758 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 359.2476 - val_mae: 0.0474\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 431.2128 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 341.1809 - val_mae: 0.0473\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 347.8854 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 328.1634 - val_mae: 0.0476\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 381.8602 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 340.8572 - val_mae: 0.0473\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 462.8497 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 335.0288 - val_mae: 0.0474\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 402.8342 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 348.3972 - val_mae: 0.0474\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 357.7204 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 317.0864 - val_mae: 0.0477\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 378.3417 - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0036 - val_mape: 329.0478 - val_mae: 0.0473\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 359.6566 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 352.5309 - val_mae: 0.0473\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.7050 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 352.6993 - val_mae: 0.0474\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 370.0498 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 365.2866 - val_mae: 0.0476\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 405.9763 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 358.0404 - val_mae: 0.0473\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 442.7776 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0037 - val_mape: 341.6162 - val_mae: 0.0476\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 368.1527 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 334.9952 - val_mae: 0.0474\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 414.3947 - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0036 - val_mape: 352.4001 - val_mae: 0.0473\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 366.0852 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 346.9904 - val_mae: 0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 392.0127 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 337.8888 - val_mae: 0.0473\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 436.2894 - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0036 - val_mape: 347.8208 - val_mae: 0.0473\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 397.0668 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 355.2025 - val_mae: 0.0473\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 443.4710 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 343.6446 - val_mae: 0.0473\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 382.5080 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 340.8487 - val_mae: 0.0473\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 412.3257 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 327.1877 - val_mae: 0.0474\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 382.0412 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 345.2225 - val_mae: 0.0472\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 402.7972 - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0036 - val_mape: 346.5906 - val_mae: 0.0474\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 434.5237 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 348.1456 - val_mae: 0.0475\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 410.0593 - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0036 - val_mape: 345.2515 - val_mae: 0.0473\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 372.7459 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 329.8935 - val_mae: 0.0473\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 370.8053 - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0036 - val_mape: 339.2221 - val_mae: 0.0473\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 418.5262 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 344.2594 - val_mae: 0.0473\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 404.4979 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 349.8417 - val_mae: 0.0473\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 354.5646 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 347.6365 - val_mae: 0.0473\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 399.0809 - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0036 - val_mape: 353.3286 - val_mae: 0.0473\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 420.3498 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 341.3048 - val_mae: 0.0473\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 389.9238 - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0036 - val_mape: 327.6576 - val_mae: 0.0474\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 400.3345 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 334.5240 - val_mae: 0.0472\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 366.3864 - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0036 - val_mape: 356.2159 - val_mae: 0.0475\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 391.7179 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 336.6477 - val_mae: 0.0473\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 377.9904 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 338.9219 - val_mae: 0.0474\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 409.0433 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 350.2029 - val_mae: 0.0475\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 390.1517 - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0036 - val_mape: 345.0067 - val_mae: 0.0473\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 393.1994 - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0036 - val_mape: 348.8324 - val_mae: 0.0473\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 489.4123 - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0036 - val_mape: 347.3586 - val_mae: 0.0474\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 11ms/step - mape: 386.3249 - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0036 - val_mape: 351.4590 - val_mae: 0.0472\n"
     ]
    }
   ],
   "source": [
    "hists = model.fit(x= [x_train, features_train, adj_train],\n",
    "                  y= y_train, verbose=verbose, epochs=500,\n",
    "                  batch_size=batch_size, #validation_split=0.1, \n",
    "                  validation_data=([x_val, features_val, adj_val], y_val),\n",
    "                  callbacks=[EarlyStopping(#monitor=\"val_mean_absolute_error\", \n",
    "                      monitor=\"val_loss\", patience=20, restore_best_weights=True)], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(hists.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.0458, 'mape': 39.7896, 'rmse': 0.0576}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted = model.predict([x_train, features_train, adj_train])\n",
    "get_metrics(y_train.flatten(), train_predicted.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.0482, 'mape': 41.9682, 'rmse': 0.0605}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted = model.predict([x_test, features_test, adj_test])\n",
    "get_metrics(y_test.flatten(), test_predicted.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_2  = y_test.reshape(y_test.shape[0],y_test.shape[1])\n",
    "pred_test_2  =  test_predicted.reshape( test_predicted.shape[0], test_predicted.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAT_test_result = pd.DataFrame(pred_test_2, index = Synthetic_ret.index[-pred_test_2.shape[0]:], columns = Synthetic_ret.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAT_test_result.to_csv(\"GAT_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
